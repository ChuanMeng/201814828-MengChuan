基于KNN与VSM的文本分类模型
{ 姓名：孟川；学号：201814828；班级：2018级学硕班；导师：陈竹敏 } 

摘要：本次实验基于KNN与VSM构建了文本分类模型。在20news-18828数据集上，经过VSM构建、KNN构建、N-fold验证集验证K值和测试集测试等实验步骤，最终发现，在K值取15的时候模型表现效果最好，可以在测试集取得87.96%的精确度。
目录
一、vector space model 构建	2
1.1 文本预处理	2
1.1.1 分词	2
1.1.2 去停止词	3
1.1.3 抽取词干	3
1.2 划分训练集与测试集	4
1.3 构建字典	5
1.4 计算TF-IDF值	6
1.4.1训练集 IDF值计算	6
1.4.2 训练集TF值计算	7
1.4.3 测试集的IDF值计算	7
1.4.4 测试集的TF值计算	8
1.5 将embeding转化为矩阵	8
二、KNN的构建	10
2.1 读取训练集和测试集的embeding矩阵	10
2.2 计算cosin similarity	10
2.3 排序	11
三、实验	12
3.1 N-fold验证集实验	12
3.2	测试集实验结果	13
四、结论	14

一、vector space model 构建
1.1 文本预处理
文本预处理会主要使用NLTK工具，所以要先进行相应的工具包安装。
 
图1 调用命令
 
图2 NLTK安装
1.1.1 分词
分词工作主要有以下三个步骤：
1.	小写化：首先用lower()方法将所有的字母小写化；
2.	去符号和数字：用string.punctuation与string.digits方法得到所有符号和数字，并用translate方法去除，需要注意一点，要将符号或者数字去除的位置加上空格，以防符号连接的单词粘在一起，形成怪异的长单词； 
3.	用NLTK实现分词：使用NLTK工具包的nltk.word_tokenize方法实现分词。 
 
图3 分词
1.1.2 去停止词
引入NLTK工具包的nltk.corpus的stopwords，具体方法为stopwords.words('english')，对分词结果属于停止词的进行过滤。
 
图4 去停止词
1.1.3 抽取词干
抽取词干使用NLTK工具包中的nltk.stem.SnowballStemmer('english')方法完成。
 
图5 抽取词干

 
图6 对分词、去停止词与抽取词干进行调用








1.2 划分训练集与测试集
测试集占整个数据集的20%，因此从20个类的原始文档中分别抽取20%作为测试集，剩余80%作为训练集，并且每个类抽取之前先用shuffle算法进行打乱，保证抽取的随机性。
最终切分的结果是，训练集文档个数为15056，测试集文档个数为3772。
 
图7 划分训练集与测试集












1.3 构建字典
本次实验构建字典的长度为15749，构建字典的时候应该注意以下几点：
1.	用dict来存储字典中的单词；
2.	只用训练集来构建字典，测试集不参与词典的构建；
3.	为了减小字典的长度，减轻计算的负担，先要计算所有词在全部文档出现的总频数，如果该单词的总频数小于10，则将其剔除，原因是该单词若总频数比较小，说明该单词属于生僻单词，对于文本分类意义不大。
 
图8 构建字典






1.4 计算TF-IDF值
1.4.1训练集 IDF值计算
字典中的每个单词针对所有文档的IDF值是一致的，但是TF值每个文档都不一致，所以IDF值只需要算一次，然后存储调用，这样更方便。

 
图9 训练集IDF计算方法体
 
图10 训练集IDF计算方法调用
 
图11 计算得到的每个单词的IDF值示例
1.4.2 训练集TF值计算
在训练集中，字典中的每个单词对于不同文档，TF值是不同的，所以在遍历词表的基础上，再需要遍历每个文档去计算TF值。
算得TF之后，再度读取已经计算好的IDF值，然后计算得训练集每个文档的TF-IDF值，将所有文档的embeding存到LIST里面保存。
 
图12 计算训练集TF-IDF方法体
 
图13 计算训练集TF-IDF方法调用
1.4.3 测试集的IDF值计算
测试集的IDF值计算不同于训练集的IDF计算，因为测试集每个样例之间是不可见的，每个测试集只能“看得见”所有训练集的文档，所以对于字典中的每个词在每条测试集中IDF的计算，每读入1条测试集，就要把这条测试集并入原始的训练集中，然后把它们视为一个文档总体，然后再计算IDF。整个计算过程比较消耗时间。
 
图14 测试集IDF计算方法体
 
图15 测试集IDF计算方法调用
1.4.4 测试集的TF值计算
字典中的每个词在测试集的TF计算与在训练集中的计算类似，得到TF值后，再与IDF相乘得到测试集的TF-IDF值。测试集的embeding单独存放在一个list中。
 
图16 测试集TF-IDF计算方法体
 
图17 测试集TF-IDF计算方法调用
1.5 将embeding转化为矩阵
为了后期KNN方便计算，在这里我使用numpy方法，将测试集与训练集的embeding转化为矩阵。有以下几个注意事项：
1.	训练集矩阵维度为15056 X 15749，测试集的矩阵维度为3772 X 15749，矩阵的每一行对应一个文档，每一列对应一个字典中的特征词。
2.	为了方便调用，将训练集和测试集的矩阵保存，保存之后VSM部分结束。
 
图18 训练集embeding

 
图19 测试集embeding

 























二、	KNN的构建
2.1 读取训练集和测试集的embeding矩阵
将VSM得到的训练集和测试集的embeding读取出来，然后再针对测试集矩阵的每一行（每个样例），去与训练集所有的样例去计算相似度，返回该条测试样例最有可能的类别，然后和真实的label相比，看是否对应。
 
图20 embeding读取
2.2 计算cosin similarity
针对每一条test样例和train样例，分别计算二者的cosin similarity，并返回结果。
 
图21 cosin similarity计算



2.3 排序
针对每一条测试样例，得到与所有的训练样例的cosin相似度的值后，按从大到小排序，然后取前K个，看哪个类贡献的样例数量最多（或者看哪个类的累计cosin相似度值最大），然后返回这个类，这个类就是KNN对本测试样例的类别预测结果。
 
图22 排序



















三、实验
3.1 N-fold验证集实验
先通过N-fold来确定KNN的最佳K值，这里我们采用5-fold验证法，验证结果如下：
 
图23 验证集结果

由上图得知，K=15的时候，在验证集上采用5-fold实现了0.8791的精确度，因此我们决定KNN在测试集上的K值为15.。
 
图24 验证集实现0.8791的精确度
 
图25 N-fold验证代码实现
3.2	测试集实验结果
最终我们以K=15的KNN在测试集上运行，最终得到的精确度为0.8796，分类正确率为87.96%。测试集上的结果见图18.
 
图26 测试集运行结果

四、结论
经过本次实验，良好的锻炼了我的代码能力，我有以下心得：
1.	KNN是一项比较有效的方法，实现简单，可以实现较高的精确度，但是实验起来吃内存、耗时间，本次实验使用服务器运行，但是运行一次仍旧需要非常长的时间。
2.	代码的优化非常关键，尽量写代码之前要进行充分的构思，尽量减少循环的使用，读取数据的时候尽量将大文件化成多个小文件，减轻内存的消耗。
3.	要加强代码的封装与规整性，加强方法的调用，减少代码的冗余度，增加代码的可读性。


